{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler# 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from scipy.stats import stats\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "import gc\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbild the model, loss and data class, including two different versions\\nversion 1:\\nseq to seq model\\nversion old:\\nthe old seq to seq model without any paramseters\\nversioin 2:\\nseq to 1 model\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bild the model, loss and data class, including two different versions\n",
    "version 1:\n",
    "seq to seq model\n",
    "version old:\n",
    "the old seq to seq model without any paramseters\n",
    "versioin 2:\n",
    "seq to 1 model\n",
    "\"\"\"\n",
    "class TS_rnn(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    scores for each piece\n",
    "    input:\n",
    "        tensor size of (batch_size, seq_len, num_dim)\n",
    "    output:\n",
    "        tensor size of (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden = 64, num_layers = 2, dropout = 0.5):\n",
    "        super(TS_rnn, self).__init__()\n",
    "        #change the structure of the network\n",
    "        num_inp = 13\n",
    "        self.rnn = torch.nn.LSTM(input_size = num_inp, hidden_size = num_hidden, num_layers = num_layers, dropout = dropout)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_hidden, 16),\n",
    "                torch.nn.Dropout(),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(16, 1)\n",
    "                )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # input of the rnn (seq_len, batch, input_size)\n",
    "        data_in = torch.transpose(inp, 0, 1)\n",
    "        # run rnn, it has two output\n",
    "        out_rnn, _ = self.rnn(data_in)\n",
    "        out_rnn = torch.transpose(out_rnn, 0, 1) # (batch_size, seq_len, num_dim)\n",
    "        # rnn the mlp\n",
    "        batch_size, seq_len, num_dim = out_rnn.shape\n",
    "        out = []\n",
    "        for i in range(seq_len):\n",
    "            tmp = self.mlp(out_rnn[:, i,:])\n",
    "            out.append(tmp)\n",
    "        # now out is list of (batch_size, 1), combine the items in the list to get the output with size (batch_size, seq_len)\n",
    "        out = torch.cat(out, 1)\n",
    "        #return out.squeeze() when the batch_size == 1, this can course trouble\n",
    "        return out\n",
    "\n",
    "class TS_rnn_old(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    scores for each piece\n",
    "    input:\n",
    "        tensor size of (batch_size, seq_len, num_dim)\n",
    "    output:\n",
    "        tensor size of (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TS_rnn_old, self).__init__()\n",
    "        #change the structure of the network\n",
    "        num_inp = 13\n",
    "        num_hidden = 64\n",
    "        self.rnn = torch.nn.LSTM(input_size = num_inp, hidden_size = num_hidden, num_layers = 2)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_hidden, 16),\n",
    "                torch.nn.Dropout(),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(16, 1)\n",
    "                )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # input of the rnn (seq_len, batch, input_size)\n",
    "        data_in = torch.transpose(inp, 0, 1)\n",
    "        # run rnn, it has two output\n",
    "        out_rnn, _ = self.rnn(data_in)\n",
    "        out_rnn = torch.transpose(out_rnn, 0, 1) # (batch_size, seq_len, num_dim)\n",
    "        # rnn the mlp\n",
    "        batch_size, seq_len, num_dim = out_rnn.shape\n",
    "        out = []\n",
    "        for i in range(seq_len):\n",
    "            tmp = self.mlp(out_rnn[:, i,:])\n",
    "            out.append(tmp)\n",
    "        # now out is list of (batch_size, 1), combine the items in the list to get the output with size (batch_size, seq_len)\n",
    "        out = torch.cat(out, 1)\n",
    "        #return out.squeeze() when the batch_size == 1, this can course trouble\n",
    "        return out\n",
    "\n",
    "class TS_rnn2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    scores only for the whole task\n",
    "    input:\n",
    "        tensor size of (batch_size, seq_len, num_dim)\n",
    "    output:\n",
    "        tensor size of (batch_size)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TS_rnn2, self).__init__()\n",
    "        #change the structure of the network\n",
    "        num_inp = 8\n",
    "        num_hidden = 64\n",
    "        self.rnn = torch.nn.LSTM(input_size = num_inp, hidden_size = num_hidden, num_layers = 2)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_hidden, 64),\n",
    "                torch.nn.Dropout(),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 1)\n",
    "                )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # input of the rnn (seq_len, batch, input_size)\n",
    "        data_in = torch.transpose(inp, 0, 1)\n",
    "        # run rnn, it has two output\n",
    "        out_rnn, _ = self.rnn(data_in)\n",
    "        out_rnn = torch.transpose(out_rnn, 0, 1) # (batch_size, seq_len, num_dim)\n",
    "        # only use the last output\n",
    "        out_rnn = out_rnn[:, -1, :].squeeze()\n",
    "        # rnn the mlp\n",
    "        out = self.mlp(out_rnn)\n",
    "        return out.squeeze()\n",
    "    \n",
    "class PDLoss(torch.nn.Module):\n",
    "    def __init__(self, p = 2):\n",
    "        super(PDLoss, self).__init__()\n",
    "        self.pd = torch.nn.PairwiseDistance(p)\n",
    "\n",
    "    def forward(self, o, t):\n",
    "        # out: (batch_size, 1)\n",
    "        out = self.pd(o, t)\n",
    "        return out.mean()\n",
    "\n",
    "class Data:\n",
    "    \"\"\"\n",
    "    data class for TS_rnn\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.data = {}\n",
    "        self.data['train_x'] = self.add_file(x).float()\n",
    "        self.data['train_y'] = self.add_file(y)[:, :, -1].float() # use the first metric tempately\n",
    "        assert(len(self.data['train_x']) == len(self.data['train_y']))\n",
    "        self.len = len(self.data['train_x'])\n",
    "\n",
    "    def add_file(self, path):\n",
    "        return torch.from_numpy(np.load(path))\n",
    "\n",
    "    def add_scores(self, path):\n",
    "        return torch.FloatTensor([float(li.rstrip('\\n')) for li in open(path)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data['train_x'][index],\n",
    "                self.data['train_y'][index])\n",
    "\n",
    "class Data2:\n",
    "    \"\"\"\n",
    "    data class for TS_rnn2\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.data = {}\n",
    "        self.data['train_x'] = self.add_file(x)\n",
    "        self.data['train_y'] = self.add_file(y)[:, :, -1] # use the first metric tempately\n",
    "        self.data['train_y'] = torch.mean(self.data['train_y'], 1)\n",
    "        assert(len(self.data['train_x']) == len(self.data['train_y']))\n",
    "        self.len = len(self.data['train_x'])\n",
    "\n",
    "    def add_file(self, path):\n",
    "        return torch.from_numpy(np.load(path))\n",
    "\n",
    "    def add_scores(self, path):\n",
    "        return torch.FloatTensor([float(li.rstrip('\\n')) for li in open(path)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data['train_x'][index],\n",
    "                self.data['train_y'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the test function\n",
    "def test_model(dl_test, model, loss):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    counter = 0\n",
    "    for batch_idx, dat in enumerate(dl_test):\n",
    "        counter += 1\n",
    "        # codes to be changed\n",
    "        inp, target = dat\n",
    "        out = model(inp)\n",
    "        lo = loss(out, target)\n",
    "        test_loss += lo.data\n",
    "    return test_loss/counter\n",
    "\n",
    "def significant_test(dl_test, model, loss):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    counter = 0\n",
    "    hit = 0\n",
    "    miss = 0\n",
    "    for batch_idx, dat in enumerate(dl_test):\n",
    "        counter += 1\n",
    "        # codes to be changed\n",
    "        inp, target = dat\n",
    "        out = model(inp)\n",
    "        #target = target.mean(dim = 1)\n",
    "        target = target[:, :].mean(dim = 1)\n",
    "        #print(out.shape)\n",
    "        #out = out.mean(dim = 1)\n",
    "        out = out[:, :].mean(dim = 1)\n",
    "        #print(out.shape)\n",
    "        if len(inp) > 5:\n",
    "            _, top_target = torch.topk(target, 1, largest=False)\n",
    "            _, top_predict = torch.topk(out, 5, largest = False)\n",
    "            if top_target in top_predict:\n",
    "                hit += 1\n",
    "            else:\n",
    "                miss += 1\n",
    "    return hit * 1.0/(hit + miss)\n",
    "\n",
    "def metric2(dl_test, model, loss):\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    hit_count = {}\n",
    "    for batch_idx, dat in enumerate(dl_test):\n",
    "        counter += 1\n",
    "        inp, target = dat\n",
    "        out = model(inp)\n",
    "        #target = target.mean(dim = 1)\n",
    "        #out = out.mean(dim = 1)\n",
    "        target = target[:, :].mean(dim = 1)\n",
    "        out = out[:, :].mean(dim = 1)\n",
    "        if len(inp) > 5:\n",
    "            _, index_top_target = torch.topk(target, 1, largest = False)\n",
    "            _, index_rank = torch.topk(out, len(target), largest = False)\n",
    "            index_rank = index_rank.tolist()\n",
    "            index_in_rank = index_rank.index(index_top_target)\n",
    "            if index_in_rank not in hit_count.keys():\n",
    "                #print('create new key')\n",
    "                hit_count[index_in_rank] = 1\n",
    "            else:\n",
    "                #print('add one')\n",
    "                hit_count[index_in_rank] = hit_count[index_in_rank] + 1\n",
    "    return hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0: 0.10382513661202186\n",
      "test 1: 0.16939890710382513\n",
      "test 2: 0.15300546448087432\n",
      "test 3: 0.15846994535519127\n",
      "test 4: 0.14754098360655737\n",
      "test 5: 0.15300546448087432\n",
      "test 6: 0.15300546448087432\n",
      "test 7: 0.17486338797814208\n",
      "test 8: 0.1366120218579235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-2263a040a225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/TS_rnn_v2/rnn_30.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../results/Dataframe_feature_test_10.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-f250a1dfb5d3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(pm, testdata)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignificant_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mme\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-541c1e165be2>\u001b[0m in \u001b[0;36msignificant_test\u001b[0;34m(dl_test, model, loss)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# codes to be changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#target = target.mean(dim = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6203b8f1a95d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdata_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# run rnn, it has two output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mout_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, seq_len, num_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# rnn the mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = {\n",
    "    'v2-44': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_6.pkl'),\n",
    "    #'v2-54': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_4.pkl'),\n",
    "    #'v2-10': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_10.pkl'),\n",
    "    #'v2-20': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_11.pkl'),\n",
    "    #'v2-30': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_14.pkl'),\n",
    "    #'v2-40': ('../models/TS_rnn_v2/rnn_30.pkl', '../results/Dataframe_feature_test_16.pkl'),\n",
    "    \"v3-44\": ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_7.pkl'),\n",
    "    #'v3-54': ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_7.pkl'),\n",
    "    #'v3-10': ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_9.pkl'),\n",
    "    #'v3-20': ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_12.pkl'),\n",
    "    #'v3-30': ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_13.pkl'),\n",
    "    #'v3-40': ('../models/TS_rnn_v3/rnn_32.pkl', '../results/Dataframe_feature_test_15.pkl'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pm, testdata):\n",
    "    # read extra test set\n",
    "    test = pd.read_pickle(testdata)\n",
    "    test_x = test.iloc[:, :650].values.reshape(len(test), 50, -1)\n",
    "    test_y = test.iloc[:, 650:].values.reshape(len(test), 50, -1)\n",
    "    np.save('../data/rnn_test_x', test_x)\n",
    "    np.save('../data/rnn_test_y', test_y)\n",
    "    loss = torch.nn.L1Loss()\n",
    "    test_x = '../data/rnn_test_x.npy'\n",
    "    test_y = '../data/rnn_test_y.npy'\n",
    "    test = Data(test_x, test_y)\n",
    "    dl_test = DataLoader(test, batch_size = 100, shuffle = True)\n",
    "    model = torch.load(pm)\n",
    "    me = 0\n",
    "    for i in range(5):\n",
    "        lo = significant_test(dl_test, model, loss)\n",
    "        me += lo\n",
    "        print('test ' + str(i)+': ' + str(lo))\n",
    "    hit_count = metric2(dl_test, model, loss)\n",
    "    hit_count = sorted(hit_count.items(), key = lambda x: x[0])\n",
    "    out = [i[1] for i in hit_count]\n",
    "    return (me, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0: 0.9125\n",
      "test 1: 0.8375\n",
      "test 2: 0.9\n",
      "test 3: 0.85\n",
      "test 4: 0.8875\n",
      "test 0: 0.7922077922077922\n",
      "test 1: 0.8311688311688312\n",
      "test 2: 0.8051948051948052\n",
      "test 3: 0.8571428571428571\n",
      "test 4: 0.7922077922077922\n"
     ]
    }
   ],
   "source": [
    "rs = {}\n",
    "for name, value in td.items():\n",
    "    rs[name] = evaluate(value[0], value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_all_supp.pickle', 'wb') as handle:\n",
    "    pickle.dump(rs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "v2-44\n",
      "(4.3875, [31, 12, 13, 4, 2, 3, 3, 5, 1, 1, 1, 1, 1, 1, 1])\n",
      "--------------\n",
      "v3-44\n",
      "(4.077922077922079, [35, 7, 10, 8, 3, 1, 4, 2, 2, 2, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for n, v in rs.items():\n",
    "    print('--------------')\n",
    "    print(n)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_pickle('../results/Dataframe_feature7.pkl')\n",
    "dat = dat.iloc[int(len(test)*0.9):,]\n",
    "dat.to_pickle('../results/Dataframe_feature_test_7.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71474"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(test)*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../models/TS_rnn_v2/rnn_30.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0: 0.15846994535519127\n",
      "test 1: 0.15846994535519127\n",
      "test 2: 0.14754098360655737\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d3137b588ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignificant_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mme\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d1fdd9232c1d>\u001b[0m in \u001b[0;36msignificant_test\u001b[0;34m(dl_test, model, loss)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# codes to be changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6203b8f1a95d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdata_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# run rnn, it has two output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mout_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, seq_len, num_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# rnn the mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "me = 0\n",
    "for i in range(10):\n",
    "    lo = significant_test(dl_test, model, loss)\n",
    "    me += lo\n",
    "    print('test ' + str(i)+': ' + str(lo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_count = metric2(dl_test, model, loss)\n",
    "hit_count = sorted(hit_count.items(), key = lambda x: x[0])\n",
    "out = [i[1] for i in hit_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [i[1] for i in hit_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
