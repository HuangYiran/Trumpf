{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "#import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler # 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from sklearn.cluster import MeanShift\n",
    "from scipy.stats import stats\n",
    "#from torch.utils.data import DataLoader\n",
    "#from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找Teile间的相似性的方法可以使用association rule吗，如果可以，应该如何从association rule生成对应的sentence。感觉这会是一个不错的题目 ------------- 即商业产品的word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts embedding\n",
    "Before doing the embedding, we should be clear, what kind of features do we need for the emebdding voctor.<br>\n",
    "like the word embedding, we train them with sentence, we need to create some 'sentence'. and the parts in one \n",
    "sentence should have some kinds of relationship.<br>\n",
    "另外还应该考虑的是：用什么embedding的方法， 因为不同embedding的方法，得到的结果是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentence Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_sentence:\n",
    "    def __init__(self, dict_parts, n = 10000):\n",
    "        \"\"\"\n",
    "        dict_parts, type of dictionary\n",
    "            store the information of each parts. similar parts are save under one key\n",
    "        n, type of int\n",
    "            set the total number of sentences that you want to generate\n",
    "        \"\"\"\n",
    "        self.dict_parts = dict_parts\n",
    "        self.n = n\n",
    "    def __iter__(self):\n",
    "        for i in range(n):\n",
    "            # choose a key randomly\n",
    "            key = random.choice(dict_parts.keys())\n",
    "            value = random[key]\n",
    "            yield self._create_sentence_form_words(value)\n",
    "    def _create_sentence_from_words(value):\n",
    "        #TODO\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../results/all_norm_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobid</th>\n",
       "      <th>Rot</th>\n",
       "      <th>Left down</th>\n",
       "      <th>right down</th>\n",
       "      <th>score</th>\n",
       "      <th>bounding box</th>\n",
       "      <th>Shapely Polygon</th>\n",
       "      <th>Area</th>\n",
       "      <th>length</th>\n",
       "      <th>area quote</th>\n",
       "      <th>convex area quote</th>\n",
       "      <th>convex area</th>\n",
       "      <th>area verhaltnis</th>\n",
       "      <th>centroid x/width</th>\n",
       "      <th>centroid y/height</th>\n",
       "      <th>width/height</th>\n",
       "      <th>num_of_corr</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>A/L</th>\n",
       "      <th>Left_down_x</th>\n",
       "      <th>Left_down_y</th>\n",
       "      <th>Right_down_y</th>\n",
       "      <th>norm_area</th>\n",
       "      <th>norm_left_down_x</th>\n",
       "      <th>norm_left_down_y</th>\n",
       "      <th>norm_right_down_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792-0_10_0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(93.0, 1.0)</td>\n",
       "      <td>(93.0, 377.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>93.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>-1.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792-0_10_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(213.0, 96.0)</td>\n",
       "      <td>(213.0, 254.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>213.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>254.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-1.772</td>\n",
       "      <td>-1.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792-0_10_2</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(139.0, 311.0)</td>\n",
       "      <td>(139.0, 494.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13...</td>\n",
       "      <td>12481.500</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>139.000</td>\n",
       "      <td>311.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>-1.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792-0_10_3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(234.0, 453.0)</td>\n",
       "      <td>(234.0, 581.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((150 128, 149 128, 149 92, 149 91, 12...</td>\n",
       "      <td>14630.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-1.971</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>234.000</td>\n",
       "      <td>453.000</td>\n",
       "      <td>581.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792-0_10_4</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(164.0, 678.0)</td>\n",
       "      <td>(164.0, 890.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>164.000</td>\n",
       "      <td>678.000</td>\n",
       "      <td>890.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Jobid    Rot       Left down      right down  score bounding box  \\\n",
       "0  792-0_10_0 90.000     (93.0, 1.0)   (93.0, 377.0)  0.000   (0.0, 0.0)   \n",
       "1  792-0_10_1  0.000   (213.0, 96.0)  (213.0, 254.0)  4.000   (0.0, 0.0)   \n",
       "2  792-0_10_2 90.000  (139.0, 311.0)  (139.0, 494.0)  4.000   (0.0, 0.0)   \n",
       "3  792-0_10_3  0.000  (234.0, 453.0)  (234.0, 581.0)  4.000   (0.0, 0.0)   \n",
       "4  792-0_10_4 90.000  (164.0, 678.0)  (164.0, 890.0)  0.000   (0.0, 0.0)   \n",
       "\n",
       "                                     Shapely Polygon      Area  length  \\\n",
       "0  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "1  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "2  POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13... 12481.500   0.339   \n",
       "3  POLYGON ((150 128, 149 128, 149 92, 149 91, 12... 14630.000  -0.032   \n",
       "4  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "\n",
       "   area quote  convex area quote  convex area  area verhaltnis  \\\n",
       "0      -0.514              0.512        1.266           -0.965   \n",
       "1      -0.789              0.560        1.192           -1.334   \n",
       "2      -1.070             -1.456       -0.100           -0.364   \n",
       "3      -1.078             -1.227        0.252           -0.577   \n",
       "4      -0.789              0.560        1.192           -1.334   \n",
       "\n",
       "   centroid x/width  centroid y/height  width/height  num_of_corr    r1    r2  \\\n",
       "0             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "1            -1.092              0.347        -0.497       -0.493 1.000 0.000   \n",
       "2            -1.348             -0.681        -0.503        0.008 0.000 1.000   \n",
       "3             0.396             -1.971        -0.316        0.409 1.000 0.000   \n",
       "4            -1.092              0.347        -0.497       -0.493 0.000 1.000   \n",
       "\n",
       "     A/L  Left_down_x  Left_down_y  Right_down_y  norm_area  norm_left_down_x  \\\n",
       "0  0.315       93.000        1.000       377.000      0.916            -1.286   \n",
       "1  0.239      213.000       96.000       254.000      0.608            -0.992   \n",
       "2 -0.461      139.000      311.000       494.000     -0.163            -1.173   \n",
       "3  0.322      234.000      453.000       581.000      0.125            -0.940   \n",
       "4  0.239      164.000      678.000       890.000      0.608            -1.112   \n",
       "\n",
       "   norm_left_down_y  norm_right_down_y  \n",
       "0            -1.994             -1.400  \n",
       "1            -1.772             -1.671  \n",
       "2            -1.271             -1.142  \n",
       "3            -0.939             -0.950  \n",
       "4            -0.414             -0.269  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for features based structure\n",
    "- create cluster based on different features and create sentences based on cluster.\n",
    "    - which is more important, the cluster with one features or the cluster with more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to get the n combination.\n",
    "def get_combinations(nc, seq, si = 0, com = []):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    nc, type of int\n",
    "        set the number of items in one combination\n",
    "    seq, type of list\n",
    "        from whom we get the items\n",
    "    si, type of int\n",
    "        only consider the items which index larger than si\n",
    "    com, type of list\n",
    "        used for recursion, should be set to [] when calling the function\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(si, len(seq)):\n",
    "        if seq[i] not in com:\n",
    "            com.append(seq[i])\n",
    "        else:\n",
    "            continue\n",
    "        if len(com) < nc:\n",
    "            com, tmp_out = get_combinations(nc, seq, i, com)\n",
    "            out.extend(tmp_out)\n",
    "        elif len(com) == nc:\n",
    "            #print(com)\n",
    "            out.append(com)\n",
    "            com = com[:-1]\n",
    "        else:\n",
    "            print('ERROR!!!')\n",
    "            #print(com)\n",
    "    return com[:-1], out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "df = data[['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width',\n",
    "        'centroid y/height', 'num_of_corr', 'A/L']]\n",
    "df = df.drop_duplicates()\n",
    "df['type'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set container and meanshift cluster model\n",
    "from sklearn.cluster import MeanShift\n",
    "df_cluster = pd.DataFrame(df['type'], index=df.index)\n",
    "ms = MeanShift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# level one\n",
    "_, items = get_combinations(1, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:07<00:00,  8.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#level two\n",
    "_, items = get_combinations(2, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:21<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#level three\n",
    "_, items = get_combinations(3, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:41<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#level four\n",
    "_, items = get_combinations(4, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [01:00<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#level five\n",
    "_, items = get_combinations(5, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:54<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#level six\n",
    "_, items = get_combinations(6, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:38<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#level seven\n",
    "_, items = get_combinations(7, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:20<00:00,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#level eifht\n",
    "_, items = get_combinations(8, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:07<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#level night\n",
    "_, items = get_combinations(9, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#level ten\n",
    "_, items = get_combinations(10, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#level eleven\n",
    "_, items = get_combinations(11, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                                                                                                                                                                                                    []\n",
       "clustering after ['norm_area']                                                                                                                                                          [None, None, None]\n",
       "clustering after ['length']                                                                                                                                                                             []\n",
       "clustering after ['area quote']                                                                                                                                                                     [None]\n",
       "clustering after ['convex area quote']                                                                                                                                                        [None, None]\n",
       "clustering after ['convex area']                                                                                                                                                              [None, None]\n",
       "clustering after ['area verhaltnis']                                                                                                                                                          [None, None]\n",
       "clustering after ['centroid x/width']                                                                                                                                                               [None]\n",
       "clustering after ['centroid y/height']                                                                                                                                                                  []\n",
       "clustering after ['num_of_corr']                                                                                                                                                                    [None]\n",
       "clustering after ['A/L']                                                                                                                                                                            [None]\n",
       "clustering after ['type']                                                                                                                                                                           [None]\n",
       "clustering after ['norm_area', 'length']                                                                                                                                                      [None, None]\n",
       "clustering after ['norm_area', 'area quote']                                                                                                                                                  [None, None]\n",
       "clustering after ['norm_area', 'convex area quote']                                                                                                                                                 [None]\n",
       "clustering after ['norm_area', 'convex area']                                                                                                                                           [None, None, None]\n",
       "clustering after ['norm_area', 'area verhaltnis']                                                                                                                                                       []\n",
       "clustering after ['norm_area', 'centroid x/width']                                                                                                                                                  [None]\n",
       "clustering after ['norm_area', 'centroid y/height']                                                                                                                                                 [None]\n",
       "clustering after ['norm_area', 'num_of_corr']                                                                                                                                                           []\n",
       "clustering after ['norm_area', 'A/L']                                                                                                                                                         [None, None]\n",
       "clustering after ['norm_area', 'type']                                                                                                                                                              [None]\n",
       "clustering after ['length', 'area quote']                                                                                                                                                               []\n",
       "clustering after ['length', 'convex area quote']                                                                                                                                                    [None]\n",
       "clustering after ['length', 'convex area']                                                                                                                                                              []\n",
       "clustering after ['length', 'area verhaltnis']                                                                                                                                                          []\n",
       "clustering after ['length', 'centroid x/width']                                                                                                                                                         []\n",
       "clustering after ['length', 'centroid y/height']                                                                                                                                                    [None]\n",
       "clustering after ['length', 'num_of_corr']                                                                                                                                                              []\n",
       "clustering after ['length', 'A/L']                                                                                                                                                                      []\n",
       "                                                                                                                                                                                               ...        \n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                                 [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                                         [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                               [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                              [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                             [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                         [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                               [None]\n",
       "clustering after ['norm_area', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                        [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L']                                         []\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                                    [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                                            [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                                  [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                 [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                            [None]\n",
       "clustering after ['length', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                  [None]\n",
       "clustering after ['length', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                           [None]\n",
       "clustering after ['area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                       [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L']                            []\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                       [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                               [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                     [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                    [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                   [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                               [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                     [None]\n",
       "clustering after ['norm_area', 'length', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                              [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                          [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                             [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                [None]\n",
       "Length: 2048, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take the cluster which menge between 10 and 30\n",
    "out = []\n",
    "df_cluster.apply(lambda x: [out.append(df['type'][x == i]) for i, j in zip(x.value_counts().index, x.value_counts().tolist()) if j < 30 and j > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "out = [i.tolist() for i in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1112 [00:00<?, ?it/s]\u001b[A\n",
      " 22%|██▏       | 246/1112 [00:00<00:00, 2451.37it/s]\u001b[A\n",
      " 47%|████▋     | 522/1112 [00:00<00:00, 2535.37it/s]\u001b[A\n",
      " 76%|███████▌  | 846/1112 [00:00<00:00, 2710.64it/s]\u001b[A\n",
      " 94%|█████████▍| 1048/1112 [00:00<00:00, 2458.22it/s]\u001b[A\n",
      "100%|██████████| 1112/1112 [00:00<00:00, 2597.44it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# create sentences from the cluster\n",
    "sentences = []\n",
    "for i in tqdm(out):\n",
    "    num_sents = random.randint(5, 20)\n",
    "    len_sents = random.randint(min(len(i), 5), min(len(i), 20))\n",
    "    counter = 0\n",
    "    for j in range(num_sents):\n",
    "        tmp = []\n",
    "        counter = 0\n",
    "        while counter < len_sents:\n",
    "            chosen = random.choice(i)\n",
    "            if str(chosen) in tmp:\n",
    "                continue\n",
    "            tmp.append(str(chosen))\n",
    "            counter = counter + 1\n",
    "        sentences.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  20,\n",
       "  24,\n",
       "  26,\n",
       "  27,\n",
       "  29,\n",
       "  33,\n",
       "  39,\n",
       "  42,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  51,\n",
       "  97,\n",
       "  112,\n",
       "  137,\n",
       "  216],\n",
       " [0, 1, 5, 6, 9, 28, 32, 36, 43, 49, 53, 57, 76, 77, 81, 114, 171, 243],\n",
       " [2, 3, 10, 22, 23, 25, 31, 37, 38, 59, 67, 73, 103],\n",
       " [0, 1, 2, 3, 6, 9, 10, 12, 14, 15, 17, 24, 33, 44, 57, 81, 112, 114, 243],\n",
       " [0,\n",
       "  1,\n",
       "  5,\n",
       "  11,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  28,\n",
       "  29,\n",
       "  33,\n",
       "  37,\n",
       "  42,\n",
       "  45,\n",
       "  46,\n",
       "  49,\n",
       "  59,\n",
       "  67,\n",
       "  73,\n",
       "  76,\n",
       "  81,\n",
       "  97,\n",
       "  103,\n",
       "  243],\n",
       " [9, 12, 15, 20, 24, 25, 27, 31, 32, 36, 38, 43, 57, 77, 112, 216],\n",
       " [7,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  20,\n",
       "  23,\n",
       "  24,\n",
       "  26,\n",
       "  27,\n",
       "  29,\n",
       "  33,\n",
       "  38,\n",
       "  42,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  51,\n",
       "  59,\n",
       "  73,\n",
       "  97,\n",
       "  103,\n",
       "  112,\n",
       "  137,\n",
       "  216],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  9,\n",
       "  10,\n",
       "  22,\n",
       "  25,\n",
       "  28,\n",
       "  31,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  39,\n",
       "  43,\n",
       "  49,\n",
       "  57,\n",
       "  67,\n",
       "  76,\n",
       "  77,\n",
       "  114],\n",
       " [0,\n",
       "  2,\n",
       "  3,\n",
       "  9,\n",
       "  10,\n",
       "  12,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  20,\n",
       "  24,\n",
       "  31,\n",
       "  32,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  49,\n",
       "  51,\n",
       "  57,\n",
       "  73,\n",
       "  76,\n",
       "  81,\n",
       "  97,\n",
       "  112,\n",
       "  216],\n",
       " [5,\n",
       "  6,\n",
       "  7,\n",
       "  11,\n",
       "  22,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  42,\n",
       "  46,\n",
       "  59,\n",
       "  67,\n",
       "  77,\n",
       "  103,\n",
       "  114,\n",
       "  137]]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the word Embedding\n",
    "# sentences = word2vec.Text8Corpus('sss.txt')\n",
    "model = word2vec.Word2Vec(sentences, min_count = 5, size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wv'] = df['type'].map(lambda x: model.wv[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4064451 , -0.14149065,  1.0258222 ,  1.0350567 ,  0.6432764 ,\n",
       "        2.049479  , -0.96673936,  0.31581807], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back to dataframe on length\n",
    "a = data.merge(df[['length', 'wv']], how = 'left', on = 'length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10', 0.9938647150993347)\n",
      "('243', 0.9927123188972473)\n",
      "('53', 0.9915392994880676)\n",
      "('39', 0.9899251461029053)\n",
      "('2', 0.9895091652870178)\n",
      "('171', 0.9883044958114624)\n",
      "('23', 0.9879540801048279)\n",
      "('33', 0.9847519993782043)\n",
      "('6', 0.9842872619628906)\n",
      "('7', 0.9832440614700317)\n",
      "('216', 0.9830256700515747)\n",
      "('137', 0.981259822845459)\n",
      "('51', 0.9788312315940857)\n",
      "('17', 0.9782271385192871)\n",
      "('15', 0.977448582649231)\n",
      "('20', 0.9770758152008057)\n",
      "('12', 0.9758028388023376)\n",
      "('26', 0.9745304584503174)\n",
      "('9', 0.974463939666748)\n",
      "('45', 0.9737380743026733)\n",
      "('24', 0.9734922051429749)\n",
      "('32', 0.9712787866592407)\n",
      "('44', 0.970125675201416)\n",
      "('0', 0.96909099817276)\n",
      "('16', 0.9671755433082581)\n",
      "('11', 0.9618031978607178)\n",
      "('27', 0.9614555835723877)\n",
      "('14', 0.9602183699607849)\n",
      "('29', 0.9502819180488586)\n",
      "('42', 0.948022723197937)\n",
      "('36', 0.9412325620651245)\n",
      "('1', 0.9391903877258301)\n",
      "('49', 0.9379599094390869)\n",
      "('43', 0.9373362064361572)\n",
      "('46', 0.9362534284591675)\n",
      "('31', 0.9187831878662109)\n",
      "('38', 0.9141314625740051)\n",
      "('25', 0.909267783164978)\n",
      "('22', 0.9038575887680054)\n",
      "('5', 0.903396487236023)\n",
      "('28', 0.8902019262313843)\n",
      "('37', 0.8847063779830933)\n",
      "('112', 0.11244648694992065)\n",
      "('57', 0.0429929681122303)\n",
      "('73', 0.04293106868863106)\n",
      "('114', 0.03314690664410591)\n",
      "('77', 0.02095387876033783)\n",
      "('59', 0.017640426754951477)\n",
      "('67', 0.013118281960487366)\n",
      "('97', 0.009385408833622932)\n"
     ]
    }
   ],
   "source": [
    "for i in model.most_similar('3', topn = 50):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobid</th>\n",
       "      <th>Rot</th>\n",
       "      <th>Left down</th>\n",
       "      <th>right down</th>\n",
       "      <th>score</th>\n",
       "      <th>bounding box</th>\n",
       "      <th>Shapely Polygon</th>\n",
       "      <th>Area</th>\n",
       "      <th>length</th>\n",
       "      <th>area quote</th>\n",
       "      <th>convex area quote</th>\n",
       "      <th>convex area</th>\n",
       "      <th>area verhaltnis</th>\n",
       "      <th>centroid x/width</th>\n",
       "      <th>centroid y/height</th>\n",
       "      <th>width/height</th>\n",
       "      <th>num_of_corr</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>A/L</th>\n",
       "      <th>Left_down_x</th>\n",
       "      <th>Left_down_y</th>\n",
       "      <th>Right_down_y</th>\n",
       "      <th>norm_area</th>\n",
       "      <th>norm_left_down_x</th>\n",
       "      <th>norm_left_down_y</th>\n",
       "      <th>norm_right_down_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792-0_10_0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(93.0, 1.0)</td>\n",
       "      <td>(93.0, 377.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>93.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>-1.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792-0_10_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(213.0, 96.0)</td>\n",
       "      <td>(213.0, 254.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>213.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>254.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-1.772</td>\n",
       "      <td>-1.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792-0_10_2</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(139.0, 311.0)</td>\n",
       "      <td>(139.0, 494.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13...</td>\n",
       "      <td>12481.500</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>139.000</td>\n",
       "      <td>311.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>-1.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792-0_10_3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(234.0, 453.0)</td>\n",
       "      <td>(234.0, 581.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((150 128, 149 128, 149 92, 149 91, 12...</td>\n",
       "      <td>14630.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-1.971</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>234.000</td>\n",
       "      <td>453.000</td>\n",
       "      <td>581.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792-0_10_4</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(164.0, 678.0)</td>\n",
       "      <td>(164.0, 890.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>164.000</td>\n",
       "      <td>678.000</td>\n",
       "      <td>890.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Jobid    Rot       Left down      right down  score bounding box  \\\n",
       "0  792-0_10_0 90.000     (93.0, 1.0)   (93.0, 377.0)  0.000   (0.0, 0.0)   \n",
       "1  792-0_10_1  0.000   (213.0, 96.0)  (213.0, 254.0)  4.000   (0.0, 0.0)   \n",
       "2  792-0_10_2 90.000  (139.0, 311.0)  (139.0, 494.0)  4.000   (0.0, 0.0)   \n",
       "3  792-0_10_3  0.000  (234.0, 453.0)  (234.0, 581.0)  4.000   (0.0, 0.0)   \n",
       "4  792-0_10_4 90.000  (164.0, 678.0)  (164.0, 890.0)  0.000   (0.0, 0.0)   \n",
       "\n",
       "                                     Shapely Polygon      Area  length  \\\n",
       "0  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "1  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "2  POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13... 12481.500   0.339   \n",
       "3  POLYGON ((150 128, 149 128, 149 92, 149 91, 12... 14630.000  -0.032   \n",
       "4  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "\n",
       "   area quote  convex area quote  convex area  area verhaltnis  \\\n",
       "0      -0.514              0.512        1.266           -0.965   \n",
       "1      -0.789              0.560        1.192           -1.334   \n",
       "2      -1.070             -1.456       -0.100           -0.364   \n",
       "3      -1.078             -1.227        0.252           -0.577   \n",
       "4      -0.789              0.560        1.192           -1.334   \n",
       "\n",
       "   centroid x/width  centroid y/height  width/height  num_of_corr    r1    r2  \\\n",
       "0             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "1            -1.092              0.347        -0.497       -0.493 1.000 0.000   \n",
       "2            -1.348             -0.681        -0.503        0.008 0.000 1.000   \n",
       "3             0.396             -1.971        -0.316        0.409 1.000 0.000   \n",
       "4            -1.092              0.347        -0.497       -0.493 0.000 1.000   \n",
       "\n",
       "     A/L  Left_down_x  Left_down_y  Right_down_y  norm_area  norm_left_down_x  \\\n",
       "0  0.315       93.000        1.000       377.000      0.916            -1.286   \n",
       "1  0.239      213.000       96.000       254.000      0.608            -0.992   \n",
       "2 -0.461      139.000      311.000       494.000     -0.163            -1.173   \n",
       "3  0.322      234.000      453.000       581.000      0.125            -0.940   \n",
       "4  0.239      164.000      678.000       890.000      0.608            -1.112   \n",
       "\n",
       "   norm_left_down_y  norm_right_down_y  \n",
       "0            -1.994             -1.400  \n",
       "1            -1.772             -1.671  \n",
       "2            -1.271             -1.142  \n",
       "3            -0.939             -0.950  \n",
       "4            -0.414             -0.269  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobid</th>\n",
       "      <th>Rot</th>\n",
       "      <th>Left down</th>\n",
       "      <th>right down</th>\n",
       "      <th>score</th>\n",
       "      <th>bounding box</th>\n",
       "      <th>Shapely Polygon</th>\n",
       "      <th>Area</th>\n",
       "      <th>length</th>\n",
       "      <th>area quote</th>\n",
       "      <th>convex area quote</th>\n",
       "      <th>convex area</th>\n",
       "      <th>area verhaltnis</th>\n",
       "      <th>centroid x/width</th>\n",
       "      <th>centroid y/height</th>\n",
       "      <th>width/height</th>\n",
       "      <th>num_of_corr</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>A/L</th>\n",
       "      <th>Left_down_x</th>\n",
       "      <th>Left_down_y</th>\n",
       "      <th>Right_down_y</th>\n",
       "      <th>norm_area</th>\n",
       "      <th>norm_left_down_x</th>\n",
       "      <th>norm_left_down_y</th>\n",
       "      <th>norm_right_down_y</th>\n",
       "      <th>wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792-0_10_0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(93.0, 1.0)</td>\n",
       "      <td>(93.0, 377.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>93.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792-0_10_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(213.0, 96.0)</td>\n",
       "      <td>(213.0, 254.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>213.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>254.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-1.772</td>\n",
       "      <td>-1.671</td>\n",
       "      <td>[-0.52308816, 0.15136395, 1.2147502, 0.7406462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792-0_10_2</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(139.0, 311.0)</td>\n",
       "      <td>(139.0, 494.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13...</td>\n",
       "      <td>12481.500</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>139.000</td>\n",
       "      <td>311.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>-1.142</td>\n",
       "      <td>[-0.4064451, -0.14149065, 1.0258222, 1.0350567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792-0_10_3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(234.0, 453.0)</td>\n",
       "      <td>(234.0, 581.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((150 128, 149 128, 149 92, 149 91, 12...</td>\n",
       "      <td>14630.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-1.971</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>234.000</td>\n",
       "      <td>453.000</td>\n",
       "      <td>581.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>[-0.38796213, 0.13429478, 0.9971617, 0.8649837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792-0_10_4</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(164.0, 678.0)</td>\n",
       "      <td>(164.0, 890.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>164.000</td>\n",
       "      <td>678.000</td>\n",
       "      <td>890.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>[-0.52308816, 0.15136395, 1.2147502, 0.7406462...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Jobid    Rot       Left down      right down  score bounding box  \\\n",
       "0  792-0_10_0 90.000     (93.0, 1.0)   (93.0, 377.0)  0.000   (0.0, 0.0)   \n",
       "1  792-0_10_1  0.000   (213.0, 96.0)  (213.0, 254.0)  4.000   (0.0, 0.0)   \n",
       "2  792-0_10_2 90.000  (139.0, 311.0)  (139.0, 494.0)  4.000   (0.0, 0.0)   \n",
       "3  792-0_10_3  0.000  (234.0, 453.0)  (234.0, 581.0)  4.000   (0.0, 0.0)   \n",
       "4  792-0_10_4 90.000  (164.0, 678.0)  (164.0, 890.0)  0.000   (0.0, 0.0)   \n",
       "\n",
       "                                     Shapely Polygon      Area  length  \\\n",
       "0  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "1  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "2  POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13... 12481.500   0.339   \n",
       "3  POLYGON ((150 128, 149 128, 149 92, 149 91, 12... 14630.000  -0.032   \n",
       "4  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "\n",
       "   area quote  convex area quote  convex area  area verhaltnis  \\\n",
       "0      -0.514              0.512        1.266           -0.965   \n",
       "1      -0.789              0.560        1.192           -1.334   \n",
       "2      -1.070             -1.456       -0.100           -0.364   \n",
       "3      -1.078             -1.227        0.252           -0.577   \n",
       "4      -0.789              0.560        1.192           -1.334   \n",
       "\n",
       "   centroid x/width  centroid y/height  width/height  num_of_corr    r1    r2  \\\n",
       "0             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "1            -1.092              0.347        -0.497       -0.493 1.000 0.000   \n",
       "2            -1.348             -0.681        -0.503        0.008 0.000 1.000   \n",
       "3             0.396             -1.971        -0.316        0.409 1.000 0.000   \n",
       "4            -1.092              0.347        -0.497       -0.493 0.000 1.000   \n",
       "\n",
       "     A/L  Left_down_x  Left_down_y  Right_down_y  norm_area  norm_left_down_x  \\\n",
       "0  0.315       93.000        1.000       377.000      0.916            -1.286   \n",
       "1  0.239      213.000       96.000       254.000      0.608            -0.992   \n",
       "2 -0.461      139.000      311.000       494.000     -0.163            -1.173   \n",
       "3  0.322      234.000      453.000       581.000      0.125            -0.940   \n",
       "4  0.239      164.000      678.000       890.000      0.608            -1.112   \n",
       "\n",
       "   norm_left_down_y  norm_right_down_y  \\\n",
       "0            -1.994             -1.400   \n",
       "1            -1.772             -1.671   \n",
       "2            -1.271             -1.142   \n",
       "3            -0.939             -0.950   \n",
       "4            -0.414             -0.269   \n",
       "\n",
       "                                                  wv  \n",
       "0  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  \n",
       "1  [-0.52308816, 0.15136395, 1.2147502, 0.7406462...  \n",
       "2  [-0.4064451, -0.14149065, 1.0258222, 1.0350567...  \n",
       "3  [-0.38796213, 0.13429478, 0.9971617, 0.8649837...  \n",
       "4  [-0.52308816, 0.15136395, 1.2147502, 0.7406462...  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for hierarchies structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for association based structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE ohne structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
