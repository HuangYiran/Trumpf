{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "#import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler # 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from sklearn.cluster import MeanShift\n",
    "from scipy.stats import stats\n",
    "#from torch.utils.data import DataLoader\n",
    "#from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找Teile间的相似性的方法可以使用association rule吗，如果可以，应该如何从association rule生成对应的sentence。感觉这会是一个不错的题目 ------------- 即商业产品的word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts embedding\n",
    "Before doing the embedding, we should be clear, what kind of features do we need for the emebdding voctor.<br>\n",
    "like the word embedding, we train them with sentence, we need to create some 'sentence'. and the parts in one \n",
    "sentence should have some kinds of relationship.<br>\n",
    "另外还应该考虑的是：用什么embedding的方法， 因为不同embedding的方法，得到的结果是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentence Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_sentence:\n",
    "    def __init__(self, dict_parts, n = 10000):\n",
    "        \"\"\"\n",
    "        dict_parts, type of dictionary\n",
    "            store the information of each parts. similar parts are save under one key\n",
    "        n, type of int\n",
    "            set the total number of sentences that you want to generate\n",
    "        \"\"\"\n",
    "        self.dict_parts = dict_parts\n",
    "        self.n = n\n",
    "    def __iter__(self):\n",
    "        for i in range(n):\n",
    "            # choose a key randomly\n",
    "            key = random.choice(dict_parts.keys())\n",
    "            value = random[key]\n",
    "            yield self._create_sentence_form_words(value)\n",
    "    def _create_sentence_from_words(value):\n",
    "        #TODO\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../results/all_norm_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobid</th>\n",
       "      <th>Rot</th>\n",
       "      <th>Left down</th>\n",
       "      <th>right down</th>\n",
       "      <th>score</th>\n",
       "      <th>bounding box</th>\n",
       "      <th>Shapely Polygon</th>\n",
       "      <th>Area</th>\n",
       "      <th>length</th>\n",
       "      <th>area quote</th>\n",
       "      <th>convex area quote</th>\n",
       "      <th>convex area</th>\n",
       "      <th>area verhaltnis</th>\n",
       "      <th>centroid x/width</th>\n",
       "      <th>centroid y/height</th>\n",
       "      <th>width/height</th>\n",
       "      <th>num_of_corr</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>A/L</th>\n",
       "      <th>Left_down_x</th>\n",
       "      <th>Left_down_y</th>\n",
       "      <th>Right_down_y</th>\n",
       "      <th>norm_area</th>\n",
       "      <th>norm_left_down_x</th>\n",
       "      <th>norm_left_down_y</th>\n",
       "      <th>norm_right_down_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792-0_10_0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(93.0, 1.0)</td>\n",
       "      <td>(93.0, 377.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>93.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>-1.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792-0_10_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(213.0, 96.0)</td>\n",
       "      <td>(213.0, 254.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>213.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>254.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-1.772</td>\n",
       "      <td>-1.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792-0_10_2</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(139.0, 311.0)</td>\n",
       "      <td>(139.0, 494.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13...</td>\n",
       "      <td>12481.500</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-1.348</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>139.000</td>\n",
       "      <td>311.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>-1.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792-0_10_3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(234.0, 453.0)</td>\n",
       "      <td>(234.0, 581.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((150 128, 149 128, 149 92, 149 91, 12...</td>\n",
       "      <td>14630.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-1.971</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>234.000</td>\n",
       "      <td>453.000</td>\n",
       "      <td>581.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792-0_10_4</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(164.0, 678.0)</td>\n",
       "      <td>(164.0, 890.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13...</td>\n",
       "      <td>18230.000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.789</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.192</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>164.000</td>\n",
       "      <td>678.000</td>\n",
       "      <td>890.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Jobid    Rot       Left down      right down  score bounding box  \\\n",
       "0  792-0_10_0 90.000     (93.0, 1.0)   (93.0, 377.0)  0.000   (0.0, 0.0)   \n",
       "1  792-0_10_1  0.000   (213.0, 96.0)  (213.0, 254.0)  4.000   (0.0, 0.0)   \n",
       "2  792-0_10_2 90.000  (139.0, 311.0)  (139.0, 494.0)  4.000   (0.0, 0.0)   \n",
       "3  792-0_10_3  0.000  (234.0, 453.0)  (234.0, 581.0)  4.000   (0.0, 0.0)   \n",
       "4  792-0_10_4 90.000  (164.0, 678.0)  (164.0, 890.0)  0.000   (0.0, 0.0)   \n",
       "\n",
       "                                     Shapely Polygon      Area  length  \\\n",
       "0  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "1  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "2  POLYGON ((20 138, 19 138, 17 138, 16 138, 0 13... 12481.500   0.339   \n",
       "3  POLYGON ((150 128, 149 128, 149 92, 149 91, 12... 14630.000  -0.032   \n",
       "4  POLYGON ((199 158, 93 158, 66 132, 0 132, 0 13... 18230.000   0.580   \n",
       "\n",
       "   area quote  convex area quote  convex area  area verhaltnis  \\\n",
       "0      -0.514              0.512        1.266           -0.965   \n",
       "1      -0.789              0.560        1.192           -1.334   \n",
       "2      -1.070             -1.456       -0.100           -0.364   \n",
       "3      -1.078             -1.227        0.252           -0.577   \n",
       "4      -0.789              0.560        1.192           -1.334   \n",
       "\n",
       "   centroid x/width  centroid y/height  width/height  num_of_corr    r1    r2  \\\n",
       "0             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "1            -1.092              0.347        -0.497       -0.493 1.000 0.000   \n",
       "2            -1.348             -0.681        -0.503        0.008 0.000 1.000   \n",
       "3             0.396             -1.971        -0.316        0.409 1.000 0.000   \n",
       "4            -1.092              0.347        -0.497       -0.493 0.000 1.000   \n",
       "\n",
       "     A/L  Left_down_x  Left_down_y  Right_down_y  norm_area  norm_left_down_x  \\\n",
       "0  0.315       93.000        1.000       377.000      0.916            -1.286   \n",
       "1  0.239      213.000       96.000       254.000      0.608            -0.992   \n",
       "2 -0.461      139.000      311.000       494.000     -0.163            -1.173   \n",
       "3  0.322      234.000      453.000       581.000      0.125            -0.940   \n",
       "4  0.239      164.000      678.000       890.000      0.608            -1.112   \n",
       "\n",
       "   norm_left_down_y  norm_right_down_y  \n",
       "0            -1.994             -1.400  \n",
       "1            -1.772             -1.671  \n",
       "2            -1.271             -1.142  \n",
       "3            -0.939             -0.950  \n",
       "4            -0.414             -0.269  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for features based structure\n",
    "- create cluster based on different features and create sentences based on cluster.\n",
    "    - which is more important, the cluster with one features or the cluster with more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to get the n combination.\n",
    "def get_combinations(nc, seq, si = 0, com = []):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    nc, type of int\n",
    "        set the number of items in one combination\n",
    "    seq, type of list\n",
    "        from whom we get the items\n",
    "    si, type of int\n",
    "        only consider the items which index larger than si\n",
    "    com, type of list\n",
    "        used for recursion, should be set to [] when calling the function\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(si, len(seq)):\n",
    "        if seq[i] not in com:\n",
    "            com.append(seq[i])\n",
    "        else:\n",
    "            continue\n",
    "        if len(com) < nc:\n",
    "            com, tmp_out = get_combinations(nc, seq, i, com)\n",
    "            out.extend(tmp_out)\n",
    "        elif len(com) == nc:\n",
    "            #print(com)\n",
    "            out.append(com)\n",
    "            com = com[:-1]\n",
    "        else:\n",
    "            print('ERROR!!!')\n",
    "            #print(com)\n",
    "    return com[:-1], out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "df = data[['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width',\n",
    "        'centroid y/height', 'num_of_corr', 'A/L']]\n",
    "df = df.drop_duplicates()\n",
    "df['type'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set container and meanshift cluster model\n",
    "from sklearn.cluster import MeanShift\n",
    "df_cluster = pd.DataFrame(df['type'], index=df.index)\n",
    "ms = MeanShift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# level one\n",
    "_, items = get_combinations(1, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:07<00:00,  8.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#level two\n",
    "_, items = get_combinations(2, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:21<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#level three\n",
    "_, items = get_combinations(3, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:41<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#level four\n",
    "_, items = get_combinations(4, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [01:00<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#level five\n",
    "_, items = get_combinations(5, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:54<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#level six\n",
    "_, items = get_combinations(6, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:38<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#level seven\n",
    "_, items = get_combinations(7, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:20<00:00,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#level eifht\n",
    "_, items = get_combinations(8, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:07<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#level night\n",
    "_, items = get_combinations(9, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#level ten\n",
    "_, items = get_combinations(10, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#level eleven\n",
    "_, items = get_combinations(11, df.columns, si = 0, com = [])\n",
    "for col in tqdm(items):\n",
    "    if col == 'type':\n",
    "        continue\n",
    "    clustering = ms.fit(df[col])\n",
    "    df_cluster.loc[:, 'clustering after ' + str(col)] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                                                                                                                                                                                                    []\n",
       "clustering after ['norm_area']                                                                                                                                                          [None, None, None]\n",
       "clustering after ['length']                                                                                                                                                                             []\n",
       "clustering after ['area quote']                                                                                                                                                                     [None]\n",
       "clustering after ['convex area quote']                                                                                                                                                        [None, None]\n",
       "clustering after ['convex area']                                                                                                                                                              [None, None]\n",
       "clustering after ['area verhaltnis']                                                                                                                                                          [None, None]\n",
       "clustering after ['centroid x/width']                                                                                                                                                               [None]\n",
       "clustering after ['centroid y/height']                                                                                                                                                                  []\n",
       "clustering after ['num_of_corr']                                                                                                                                                                    [None]\n",
       "clustering after ['A/L']                                                                                                                                                                            [None]\n",
       "clustering after ['type']                                                                                                                                                                           [None]\n",
       "clustering after ['norm_area', 'length']                                                                                                                                                      [None, None]\n",
       "clustering after ['norm_area', 'area quote']                                                                                                                                                  [None, None]\n",
       "clustering after ['norm_area', 'convex area quote']                                                                                                                                                 [None]\n",
       "clustering after ['norm_area', 'convex area']                                                                                                                                           [None, None, None]\n",
       "clustering after ['norm_area', 'area verhaltnis']                                                                                                                                                       []\n",
       "clustering after ['norm_area', 'centroid x/width']                                                                                                                                                  [None]\n",
       "clustering after ['norm_area', 'centroid y/height']                                                                                                                                                 [None]\n",
       "clustering after ['norm_area', 'num_of_corr']                                                                                                                                                           []\n",
       "clustering after ['norm_area', 'A/L']                                                                                                                                                         [None, None]\n",
       "clustering after ['norm_area', 'type']                                                                                                                                                              [None]\n",
       "clustering after ['length', 'area quote']                                                                                                                                                               []\n",
       "clustering after ['length', 'convex area quote']                                                                                                                                                    [None]\n",
       "clustering after ['length', 'convex area']                                                                                                                                                              []\n",
       "clustering after ['length', 'area verhaltnis']                                                                                                                                                          []\n",
       "clustering after ['length', 'centroid x/width']                                                                                                                                                         []\n",
       "clustering after ['length', 'centroid y/height']                                                                                                                                                    [None]\n",
       "clustering after ['length', 'num_of_corr']                                                                                                                                                              []\n",
       "clustering after ['length', 'A/L']                                                                                                                                                                      []\n",
       "                                                                                                                                                                                               ...        \n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                                 [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                                         [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                               [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                              [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                             [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                         [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                               [None]\n",
       "clustering after ['norm_area', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                        [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L']                                         []\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                                    [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                                            [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                                  [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                 [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                            [None]\n",
       "clustering after ['length', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                                  [None]\n",
       "clustering after ['length', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                           [None]\n",
       "clustering after ['area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                       [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L']                            []\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'type']                       [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'A/L', 'type']                               [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'num_of_corr', 'A/L', 'type']                                     [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                    [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                   [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                               [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                                     [None]\n",
       "clustering after ['norm_area', 'length', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                              [None]\n",
       "clustering after ['norm_area', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                          [None]\n",
       "clustering after ['length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                             [None]\n",
       "clustering after ['norm_area', 'length', 'area quote', 'convex area quote', 'convex area', 'area verhaltnis', 'centroid x/width', 'centroid y/height', 'num_of_corr', 'A/L', 'type']                [None]\n",
       "Length: 2048, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take the cluster which menge between 10 and 30\n",
    "out = []\n",
    "df_cluster.apply(lambda x: [out.append(df['type'][x == i]) for i, j in zip(x.value_counts().index, x.value_counts().tolist()) if j < 30 and j > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "out = [i.tolist() for i in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1112 [00:00<?, ?it/s]\u001b[A\n",
      " 22%|██▏       | 246/1112 [00:00<00:00, 2451.37it/s]\u001b[A\n",
      " 47%|████▋     | 522/1112 [00:00<00:00, 2535.37it/s]\u001b[A\n",
      " 76%|███████▌  | 846/1112 [00:00<00:00, 2710.64it/s]\u001b[A\n",
      " 94%|█████████▍| 1048/1112 [00:00<00:00, 2458.22it/s]\u001b[A\n",
      "100%|██████████| 1112/1112 [00:00<00:00, 2597.44it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# create sentences from the cluster\n",
    "sentences = []\n",
    "for i in tqdm(out):\n",
    "    num_sents = random.randint(5, 20)\n",
    "    len_sents = random.randint(min(len(i), 5), min(len(i), 20))\n",
    "    counter = 0\n",
    "    for j in range(num_sents):\n",
    "        tmp = []\n",
    "        counter = 0\n",
    "        while counter < len_sents:\n",
    "            chosen = random.choice(i)\n",
    "            if str(chosen) in tmp:\n",
    "                continue\n",
    "            tmp.append(str(chosen))\n",
    "            counter = counter + 1\n",
    "        sentences.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the word Embedding\n",
    "# sentences = word2vec.Text8Corpus('sss.txt')\n",
    "model = word2vec.Word2Vec(sentences, min_count = 5, size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wv'] = df['type'].map(lambda x: model.wv[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4064451 , -0.14149065,  1.0258222 ,  1.0350567 ,  0.6432764 ,\n",
       "        2.049479  , -0.96673936,  0.31581807], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back to dataframe on length\n",
    "data = data.merge(df[['length', 'wv']], how = 'inner', on = 'length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobid</th>\n",
       "      <th>Rot</th>\n",
       "      <th>Left down</th>\n",
       "      <th>right down</th>\n",
       "      <th>score</th>\n",
       "      <th>bounding box</th>\n",
       "      <th>Shapely Polygon</th>\n",
       "      <th>Area</th>\n",
       "      <th>length</th>\n",
       "      <th>area quote</th>\n",
       "      <th>convex area quote</th>\n",
       "      <th>convex area</th>\n",
       "      <th>area verhaltnis</th>\n",
       "      <th>centroid x/width</th>\n",
       "      <th>centroid y/height</th>\n",
       "      <th>width/height</th>\n",
       "      <th>num_of_corr</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>A/L</th>\n",
       "      <th>Left_down_x</th>\n",
       "      <th>Left_down_y</th>\n",
       "      <th>Right_down_y</th>\n",
       "      <th>norm_area</th>\n",
       "      <th>norm_left_down_x</th>\n",
       "      <th>norm_left_down_y</th>\n",
       "      <th>norm_right_down_y</th>\n",
       "      <th>wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792-0_10_0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(93.0, 1.0)</td>\n",
       "      <td>(93.0, 377.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>93.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-1.286</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792-0_11_28</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(977.0, 741.0)</td>\n",
       "      <td>(977.0, 833.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>977.000</td>\n",
       "      <td>741.000</td>\n",
       "      <td>833.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.882</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792-0_11_38</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1824.0, 1105.0)</td>\n",
       "      <td>(1824.0, 1197.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1824.000</td>\n",
       "      <td>1105.000</td>\n",
       "      <td>1197.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.959</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.408</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792-0_12_28</td>\n",
       "      <td>90.000</td>\n",
       "      <td>(614.0, 878.0)</td>\n",
       "      <td>(614.0, 1254.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>614.000</td>\n",
       "      <td>878.000</td>\n",
       "      <td>1254.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.533</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792-0_12_32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1771.0, 1058.0)</td>\n",
       "      <td>(1771.0, 1150.0)</td>\n",
       "      <td>4.000</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ...</td>\n",
       "      <td>20525.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1.266</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1771.000</td>\n",
       "      <td>1058.000</td>\n",
       "      <td>1150.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.829</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.304</td>\n",
       "      <td>[-0.40866196, 0.133643, 1.0462157, 0.6165552, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Jobid    Rot         Left down        right down  score bounding box  \\\n",
       "0   792-0_10_0 90.000       (93.0, 1.0)     (93.0, 377.0)  0.000   (0.0, 0.0)   \n",
       "1  792-0_11_28  0.000    (977.0, 741.0)    (977.0, 833.0)  4.000   (0.0, 0.0)   \n",
       "2  792-0_11_38  0.000  (1824.0, 1105.0)  (1824.0, 1197.0)  0.000   (0.0, 0.0)   \n",
       "3  792-0_12_28 90.000    (614.0, 878.0)   (614.0, 1254.0)  0.000   (0.0, 0.0)   \n",
       "4  792-0_12_32  0.000  (1771.0, 1058.0)  (1771.0, 1150.0)  4.000   (0.0, 0.0)   \n",
       "\n",
       "                                     Shapely Polygon      Area  length  \\\n",
       "0  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "1  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "2  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "3  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "4  POLYGON ((159 49, 167 44, 168 44, 308 44, 308 ... 20525.000   0.847   \n",
       "\n",
       "   area quote  convex area quote  convex area  area verhaltnis  \\\n",
       "0      -0.514              0.512        1.266           -0.965   \n",
       "1      -0.514              0.512        1.266           -0.965   \n",
       "2      -0.514              0.512        1.266           -0.965   \n",
       "3      -0.514              0.512        1.266           -0.965   \n",
       "4      -0.514              0.512        1.266           -0.965   \n",
       "\n",
       "   centroid x/width  centroid y/height  width/height  num_of_corr    r1    r2  \\\n",
       "0             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "1             0.733              2.238         0.560        0.910 1.000 0.000   \n",
       "2             0.733              2.238         0.560        0.910 1.000 0.000   \n",
       "3             0.733              2.238         0.560        0.910 0.000 1.000   \n",
       "4             0.733              2.238         0.560        0.910 1.000 0.000   \n",
       "\n",
       "    A/L  Left_down_x  Left_down_y  Right_down_y  norm_area  norm_left_down_x  \\\n",
       "0 0.315       93.000        1.000       377.000      0.916            -1.286   \n",
       "1 0.315      977.000      741.000       833.000      0.916             0.882   \n",
       "2 0.315     1824.000     1105.000      1197.000      0.916             2.959   \n",
       "3 0.315      614.000      878.000      1254.000      0.916            -0.008   \n",
       "4 0.315     1771.000     1058.000      1150.000      0.916             2.829   \n",
       "\n",
       "   norm_left_down_y  norm_right_down_y  \\\n",
       "0            -1.994             -1.400   \n",
       "1            -0.267             -0.395   \n",
       "2             0.582              0.408   \n",
       "3             0.052              0.533   \n",
       "4             0.472              0.304   \n",
       "\n",
       "                                                  wv  \n",
       "0  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  \n",
       "1  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  \n",
       "2  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  \n",
       "3  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  \n",
       "4  [-0.40866196, 0.133643, 1.0462157, 0.6165552, ...  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for hierarchies structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE for association based structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PE ohne structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
