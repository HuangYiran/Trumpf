{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler# 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from scipy.stats import stats\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "import gc\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch gpu\n",
    "\n",
    "#### 判断GPU是否可用：\n",
    "- if torch.cuda.is_available():\n",
    "#### 数据迁移\n",
    "- Tensor: 不论是什么类型的Tensor，一律直接使用方法.cuda()即可\n",
    "- Variable: 同样只需要使用.cuda()即可实现\n",
    "- .cuda()操作默认使用GPU 0也就是第一张显卡来进行操作。当我们想要存储在其他显卡中时可以使用.cuda(<显卡号数>)来将数据存储在指定的显卡中\n",
    "- 对于不用存储位置的变量，我们是不可以对他们直接进行计算的。\n",
    "    - 换句话说torch.FloatTensor是不可以直接与torch.cuda.FloatTensor进行基本运算的。位于不同GPU显存上的数据也是不能直接进行计算的\n",
    "- 对于Variable，其实就仅仅是一种能够记录操作信息并且能够自动求导的容器，实际上的关键信息并不在Variable本身，而更应该侧重于Variable中存储的data\n",
    "\n",
    "#### 模型迁移\n",
    "- linear = torch.nn.Linear(2, 2)<br>\n",
    "linaer_cuda = linear.cuda()\n",
    "- 自己模型的迁移\n",
    "    - 对于自己创建的模型类，由于继承了torch.nn.Module，则可同样使用.cuda()来将模型中用到的所有的参数都存储到显存中去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test gpu "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
