{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Tree\n",
    "### MC_note\n",
    "##### attributes\n",
    "- state, type of list ???\n",
    "- edges, type of list\n",
    "- N, type of int\n",
    "    - number of times, the note been explored\n",
    "- id, type of string\n",
    "    - identify number\n",
    "\n",
    "##### method\n",
    "- add_edge()\n",
    "- add_edges()\n",
    "- is_leaf()\n",
    "    - return bool\n",
    "- get_N()\n",
    "- get_state()\n",
    "\n",
    "### MC_edge\n",
    "##### attributes\n",
    "- action, type of string\n",
    "- in_node, type of MC_note\n",
    "- out_node, type of MC_note\n",
    "- N, type of int\n",
    "- id, type of string\n",
    "- Q, type of double\n",
    "- U, action bonus\n",
    "- W, type of double\n",
    "- P, type of double\n",
    "\n",
    "##### methods\n",
    "- get_in_node()\n",
    "- get_out_node()\n",
    "- get_state()\n",
    "    - return (Q, U, W, N, P)\n",
    "- get_value()\n",
    "- recalculate_value()\n",
    "- set_q(q)\n",
    "\n",
    "### MC_tree\n",
    "##### attributes\n",
    "- root, type of mc_node\n",
    "- path, type of list\n",
    "- tree, dictionary\n",
    "- cpuct\n",
    "\n",
    "##### methods\n",
    "- add_node()\n",
    "- back_fill()\n",
    "- expansion()\n",
    "- selection()\n",
    "- set_root()\n",
    "- simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_node():\n",
    "    def __init__(self, state, N = 0):\n",
    "        self.state = state\n",
    "        self.id = self.state.get_id()\n",
    "        self.N = N\n",
    "        self.edges = []\n",
    "    def add_edge(self, e):\n",
    "        self.edges.append(e)\n",
    "    def add_edges(self, es):\n",
    "        self.edges.extend(es)\n",
    "    def is_leaf(self):\n",
    "        if len(self.edges) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "    def get_N(self):\n",
    "        return self.N\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "class MC_edge():\n",
    "    def __init__(self, action, in_node, out_node, priori):\n",
    "        self.action = action\n",
    "        self.in_node = in_node\n",
    "        self.out_node = out_node\n",
    "        self.id = in_node.get_id() + '-' + out_node.get_id()\n",
    "        self.N = 0\n",
    "        self.W = 0\n",
    "        self.Q = 0\n",
    "        self.U = priori\n",
    "        self.P = priori # 获胜的概率，由网络得到\n",
    "        self.value = self.Q + self.U\n",
    "    def get_in_node(self):\n",
    "        return self.in_node\n",
    "    def get_out_node(self):\n",
    "        return self.out_node\n",
    "    def get_action(self):\n",
    "        return self.action\n",
    "    def get_state(self):\n",
    "        return (self.Q, self.U, self.W, self.N, self.P)\n",
    "    def get_value(self):\n",
    "        # return the value of the edge, the one here is just for test --------------------\n",
    "        # should add an new attribute value for the class edge???? -----------------------\n",
    "        return self.value\n",
    "    def set_Q(q):\n",
    "        self.Q = q\n",
    "\n",
    "class MC_tree():\n",
    "    def __init__(self, root_state, cpuct, logger = None):\n",
    "        self.root = MC_node(root_state)\n",
    "        self.path = []\n",
    "        self.tree = {}\n",
    "        self.cpuct = cpuct\n",
    "        self.add_node(self.root)\n",
    "    def add_node(self, node):\n",
    "        if node.get_id() not in self.tree.keys():\n",
    "            self.tree[node.get_id()] = node\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"node exist\")\n",
    "            return 0\n",
    "    def back_fill(self, value):\n",
    "        # update all the node and edge in the path\n",
    "        #   - N add 1 for each edge\n",
    "        #   - N add 1 for each Node \n",
    "        #   - recalculate the Q and W value of edge according to the new N value.\n",
    "        for edge in self.path:\n",
    "            edge.N += 1\n",
    "            edge.in_node.N += 1\n",
    "            edge.W = edge.W + value\n",
    "            edge.Q = edge.W/edge.N\n",
    "            edge.U = (self.cpuct * math.sqrt(edge.in_node.N) * edge.P)/ edge.N\n",
    "            edge.value = edge.Q + edge.U\n",
    "    def expansion(self, leaf, actions, states, values):\n",
    "        # values here is just the output of the p_net, \n",
    "        # still not sure what kind of infos should be setted to the edge here ----------------\n",
    "        # TODO\n",
    "        # get the leaf node\n",
    "        for action, state, value in zip(actions, states, values):\n",
    "            out_node = MC_node(state)\n",
    "            edge = MC_edge(action, leaf, out_node, value)\n",
    "            leaf.add_edge(edge)\n",
    "            self.add_node(edge.get_out_node())\n",
    "    def selection(self, root, for_suggestion = False):\n",
    "        # move to the leaf and save the path  \n",
    "        self.path = []\n",
    "        current_node = root\n",
    "        #current_node = MC_node(current_state)\n",
    "        if current_node.get_id() not in self.tree.keys():\n",
    "            return current_node, self.path\n",
    "        else:\n",
    "            while not current_node.is_leaf():\n",
    "                if not for_suggestion:\n",
    "                    tmp_edge = max(current_node.edges, key= lambda x: x.get_value())\n",
    "                else:\n",
    "                    tmp_edge = max(current_node.edges, key= lambda x: x.Q)\n",
    "                current_node = tmp_edge.get_out_node()\n",
    "                self.path.append(tmp_edge)\n",
    "            return current_node, self.path\n",
    "    def set_root(self, node):\n",
    "        self.root = node\n",
    "        path = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "### Agent\n",
    "##### attributes\n",
    "- game\n",
    "- root_state\n",
    "- mct\n",
    "\n",
    "\n",
    "##### methods\n",
    "- evaluate_leaf_state()\n",
    "- get_suggestion()\n",
    "- simulation()\n",
    "- take_action()\n",
    "- train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#应该区分root和current state\n",
    "class Agent():\n",
    "    def __init__(self, game, cpuct, logger = None):\n",
    "        self.game = game\n",
    "        self.root_state = game.get_current_state()\n",
    "        self.mct = MC_tree(self.root_state, cpuct)\n",
    "        #self.p_net = p_net\n",
    "    def episode(self):\n",
    "        #print('======= Selection ========')\n",
    "        leaf,_ = self.mct.selection(self.mct.root)\n",
    "        # test if the state of leaf staying in the done position\n",
    "        #  - yes, get the reward and fill back\n",
    "        #  - no, do the expansion of the leaf\n",
    "        if self.game.is_done(leaf.get_state()):\n",
    "            end_reward = self.game.get_reward(leaf.get_state(), True)\n",
    "        else:\n",
    "            #print('======= expansion ==========')\n",
    "            available_actions, states, values = self.evaluate_leaf_state(leaf.get_state())\n",
    "            self.mct.expansion(leaf, available_actions, states, values)\n",
    "            #print('======= simulation =========')\n",
    "            #end_reward = self.simulation(copy.deepcopy(leaf.get_state()))\n",
    "            end_reward =self.simulation_with_random_reward(copy.deepcopy(leaf.get_state()))\n",
    "        #print('======= back fill =========')\n",
    "        self.mct.back_fill(end_reward)\n",
    "        #print('======= end ========')\n",
    "    def aborded_evaluate_leaf_state(self, state_leaf):\n",
    "        \"\"\"\n",
    "        ABORDED!!!\n",
    "        input:\n",
    "          state_leaf, type of Node\n",
    "        output:\n",
    "          available_actions, type of list of action \n",
    "          states, type of list of State\n",
    "          values, type of list of float\n",
    "        \"\"\"\n",
    "        #state_leaf = leaf.get_state()\n",
    "        available_actions = self.game.get_available_actions(state_leaf)\n",
    "        states = []\n",
    "        values = []\n",
    "        for action in available_actions:\n",
    "            new_state = self.simulate_action(copy.deepcopy(state_leaf), action)\n",
    "            value_new_state = self.game.get_reward(new_state)\n",
    "            states.append(new_state)\n",
    "            values.append(value_new_state)\n",
    "        return available_actions, states, values\n",
    "    def evaluate_leaf_state(self, state_leaf):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          state_leaf, type of Node\n",
    "        output:\n",
    "          available_actions, type of list of action\n",
    "          states, type of list of State\n",
    "          values, type of list of float\n",
    "        \"\"\"\n",
    "        available_actions = self.game.get_available_actions(state_leaf)\n",
    "        states = [self.simulate_action(copy.deepcopy(state_leaf), action) for action in available_actions]\n",
    "        values = self.game.get_reward_batch(states)\n",
    "        return available_actions, states, values\n",
    "    def get_note_suggestion(self):\n",
    "        tmp_edge = max(self.mct.root.edges, key= lambda x: x.Q)\n",
    "        return tmp_edge.get_action()\n",
    "    def get_seq_suggestion(self):\n",
    "        # we can not use selection to get the suggestion because of the exporation part\n",
    "        # what should we do here, here we use win rate\n",
    "        # TODO \n",
    "        #???????????????????????????????\n",
    "        leaf, path = self.mct.selection(self.mct.root, True)\n",
    "        path = [e.get_action() for e in path]\n",
    "        if self.game.is_done(leaf.get_state()):\n",
    "            return path\n",
    "        else:\n",
    "            current_state = leaf.get_state()\n",
    "            while not self.game.is_done(current_state):\n",
    "                actions, states, values = self.evaluate_leaf_state(current_state)\n",
    "                action, current_state, _ = max(zip(actions, states, values), key = lambda x: x[2])\n",
    "                path.append(action)\n",
    "            return path\n",
    "    def simulate_action(self, cuu_state, action):\n",
    "        return self.game.simulate_action(cuu_state, action)\n",
    "    def simulation(self, tmp_state):\n",
    "        while not self.game.is_done(tmp_state):\n",
    "            #print('+++'+str(tmp_state.state))\n",
    "            #print('++++')\n",
    "            #print(tmp_state)\n",
    "            actions, states, values = self.evaluate_leaf_state(tmp_state)\n",
    "            #for state in states:\n",
    "            #    print(state.state)\n",
    "            #print(states, values)\n",
    "            action, _, _ = max(zip(actions, states, values), key = lambda x: x[2])\n",
    "            self.simulate_action(tmp_state, action)\n",
    "        return self.game.get_reward(tmp_state, True)\n",
    "    def simulation_with_random_reward(self, tmp_state):\n",
    "        while not self.game.is_done(tmp_state):\n",
    "            available_actions = self.game.get_available_actions(tmp_state)\n",
    "            action = random.choice(available_actions)\n",
    "            self.simulate_action(tmp_state, action)\n",
    "        return self.game.get_reward(tmp_state, True)\n",
    "    def take_action(self, action):\n",
    "        # return the state after taking the action.\n",
    "        self.game.take_action()\n",
    "        self.root = self.game.get_current_state()\n",
    "    def train_network():\n",
    "        # could the episode data used to train the model again??? ---> no\n",
    "        # shoud i add another model to the to predict the result and the simulation step just use random choose\n",
    "        # it can enfast the process and verringt the error\n",
    "        # then i can use the mcst to generate some data, and calculate the real answer. \n",
    "        # then used these data to train the model again.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d = max(zip(['a', 'b', 'c'], [1, 3, 2]), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game\n",
    "### Game(abstract)\n",
    "##### abstractmethods\n",
    "- get_available_actions(self, state)\n",
    "- get_current_state(self)\n",
    "- get_end_reword(self)\n",
    "- is_done(self, state)\n",
    "- restore_game(self)\n",
    "- take_action(self, action)\n",
    "### TS\n",
    "##### attributes\n",
    "- lens\n",
    "- thread\n",
    "- value_network\n",
    "- restore_game\n",
    "##### methods:\n",
    "- get_available_actions(self, state)\n",
    "- get_current_state(self)\n",
    "- get_end_reword(self)\n",
    "- is_done(self, state)\n",
    "- restore_game(self)\n",
    "- take_action(self, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(metaclass = ABCMeta):\n",
    "    @abstractmethod\n",
    "    def get_available_actions(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          state, can be any kind of type\n",
    "        output:\n",
    "          actions: list of action, action should be string\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def get_current_state(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def is_done(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          state\n",
    "        output:\n",
    "          out: if the game is done return the result, else return 0\n",
    "        \"\"\"\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def restore_game(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def simulate_action(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def take_action(self):\n",
    "        pass\n",
    "\n",
    "class TS(Game):\n",
    "    def __init__(self, lens, thread, value_network):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          lens, type of int\n",
    "              total number of parts\n",
    "          thread, type of float\n",
    "              value used to decide, weather the seq is good or not\n",
    "          value_network, type of pkl\n",
    "              neural network, that used to output the finalpunkt.\n",
    "        \"\"\"\n",
    "        super(TS, self).__init__()\n",
    "        self.polygons = pd.read_pickle('../results/all_norm_features_plus_we.pkl')\n",
    "        self.actions = self._load_available_actions()\n",
    "        self.lens = lens\n",
    "        self.thread = thread\n",
    "        self.value_network = value_network   \n",
    "        self.restore_game()\n",
    "    def get_available_actions(self, state):\n",
    "        return self.actions\n",
    "    def get_current_state(self): \n",
    "        return self.current_state\n",
    "    def get_original_state(self):\n",
    "        return State([])\n",
    "    def get_reward(self, state, is_done = False):\n",
    "        # not tested jet\n",
    "        inp_nn = self._transform_state_to_input(state)\n",
    "        out_nn = self.value_network(inp_nn)\n",
    "        score = self._transform_output_to_value(out_nn)\n",
    "        # for test\n",
    "        #score = np.std([float(i) for i in state.state])\n",
    "        # the thread should not be constant \n",
    "        #TODO\n",
    "        if not is_done:\n",
    "            return score\n",
    "        if score <= self.thread:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def get_reward_batch(self, states):\n",
    "        inp_nn = self._transform_state_to_input_batch(states)\n",
    "        out_nn = self.value_network(inp_nn)\n",
    "        scores = self._transform_output_to_value_batch(out_nn)\n",
    "        return scores\n",
    "    def _load_available_actions(self):\n",
    "        self.parts = self.polygons['type'].tolist()\n",
    "        self.rotations = [0, 90]\n",
    "        actions = []\n",
    "        num_parts = 54\n",
    "        num_rotations = 2\n",
    "        for i in self.parts:\n",
    "            for j in self.rotations:\n",
    "                actions.append((i, j))\n",
    "        return actions\n",
    "    def _transform_state_to_input(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          state, type of State\n",
    "        output:\n",
    "          out, type of FloatTensor\n",
    "        \"\"\"\n",
    "        out = transform_state_to_input(state.state, self.polygons)\n",
    "        return torch.FloatTensor(out)\n",
    "    def _transform_state_to_input_batch(self, states):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          states, type of list of State\n",
    "        output:\n",
    "          out, type of FloatTensor\n",
    "        \"\"\"\n",
    "        states = [i.state for i in states]\n",
    "        out = transform_state_to_input_batch(states, self.polygons)\n",
    "        return out\n",
    "    def _transform_output_to_value(self, output):\n",
    "        # not tested jet\n",
    "        return output.mean().squeeze()\n",
    "    def _transform_output_to_value_batch(self, output):\n",
    "        #TODO ---------------------------------------------------------\n",
    "        return output.mean(dim = 1)\n",
    "    def is_done(self, state):\n",
    "        if len(state.state) == self.lens:\n",
    "            # done\n",
    "            return True\n",
    "        else:\n",
    "            # not jet\n",
    "            return False\n",
    "    def restore_game(self):\n",
    "        self.current_state = self.get_original_state()\n",
    "    def simulate_action(self, cuu_state, action):\n",
    "        cuu_state.take_action(action)\n",
    "        return cuu_state\n",
    "    def take_action(self, action):\n",
    "        # change state after taking the action\n",
    "        self.current_state.take_action(action)\n",
    "                \n",
    "class State():\n",
    "    def __init__(self, state):\n",
    "        \"\"\"\n",
    "        !!!!!\n",
    "        problematic, can not create new state without an old one\n",
    "        or noly can create string new state\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.id = str(self.state)\n",
    "    def __len__(self):\n",
    "        return len(self.state)\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "    def take_action(self, action):\n",
    "        \"\"\"\n",
    "        !!!!!!\n",
    "        only for simplify \n",
    "        Normally, State class should not contain this function. only the game can tell the next state\n",
    "        not the state itself.\n",
    "        \"\"\"\n",
    "        # action here should be type of tuple (Part, rotation)\n",
    "        self.state.append(action)\n",
    "        self.id = str(self.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type TS_rnn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type TS_rnn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type TS_rnn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('../models/rnn_50.pkl')\n",
    "game = TS(50, 2.45, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial agent\n",
    "agent = Agent(game, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load agent\n",
    "with open('../results/seq_selection_agent.pkl', 'rb') as f:\n",
    "    agent = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-b2f73bc70d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-2f58471fa9b4>\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#print('======= expansion ==========')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mavailable_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_leaf_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print('======= simulation =========')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-2f58471fa9b4>\u001b[0m in \u001b[0;36mevaluate_leaf_state\u001b[0;34m(self, state_leaf)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mavailable_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_available_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_note_suggestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-574e5728bf10>\u001b[0m in \u001b[0;36mget_reward_batch\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_reward_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0minp_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_state_to_input_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mout_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_output_to_value_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-574e5728bf10>\u001b[0m in \u001b[0;36m_transform_state_to_input_batch\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m    102\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_state_to_input_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform_output_to_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-d32a9d89499f>\u001b[0m in \u001b[0;36mtransform_state_to_input_batch\u001b[0;34m(states, df)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform_state_to_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_state_to_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-d32a9d89499f>\u001b[0m in \u001b[0;36mtransform_state_to_input\u001b[0;34m(state, df)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdf_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rotation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m90\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    422\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5420\u001b[0m             b = make_block(\n\u001b[0;32m-> 5421\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5422\u001b[0m                 placement=placement)\n\u001b[1;32m   5423\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5565\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5565\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m   5873\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5874\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[0;32m-> 5875\u001b[0;31m                                        fill_value=fill_value)\n\u001b[0m\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1611\u001b[0m             \u001b[0;31m# check for promotion based on types only (do this first because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# it's faster than computing a mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m                 \u001b[0;31m# check if promotion is actually required based on indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_promote\u001b[0;34m(dtype, fill_value)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# returns tuple of (dtype, fill_value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;31m# for now: refuse to upcast datetime64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# (this is because datetime64 will not implicitly upconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    agent.episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_note_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sug = agent.get_seq_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.mct.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['1', '6']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-11c6edb1304a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"['1', '6']\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"['1', '6']\""
     ]
    }
   ],
   "source": [
    "agent.mct.tree[\"['1', '6']\"].N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/test.pkl', 'wb') as f:\n",
    "    pickle.dump(agent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/test.pkl', 'rb') as f:\n",
    "    agent = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = agent.get_seq_suggestion()\n",
    "a = [float(i) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std  = State(sug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7130, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.7130, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.7130, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_reward(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 90),\n",
       " (15, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (8, 0),\n",
       " (48, 0),\n",
       " (42, 90),\n",
       " (2, 0),\n",
       " (12, 90),\n",
       " (48, 90),\n",
       " (0, 0),\n",
       " (27, 0),\n",
       " (16, 0),\n",
       " (45, 0),\n",
       " (23, 90),\n",
       " (21, 0),\n",
       " (7, 0),\n",
       " (48, 0),\n",
       " (0, 0),\n",
       " (35, 0),\n",
       " (2, 90),\n",
       " (27, 90),\n",
       " (0, 0),\n",
       " (37, 90),\n",
       " (6, 90),\n",
       " (19, 0),\n",
       " (2, 90),\n",
       " (24, 0),\n",
       " (8, 90),\n",
       " (14, 0),\n",
       " (17, 90),\n",
       " (2, 0),\n",
       " (11, 90),\n",
       " (27, 0),\n",
       " (22, 90),\n",
       " (29, 90),\n",
       " (24, 0),\n",
       " (6, 90),\n",
       " (13, 90),\n",
       " (27, 0),\n",
       " (2, 90),\n",
       " (27, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (38, 90),\n",
       " (27, 0),\n",
       " (0, 90),\n",
       " (45, 90),\n",
       " (42, 0),\n",
       " (53, 90)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self defined Models and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS_rnn(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    scores for each piece\n",
    "    input:\n",
    "        tensor size of (batch_size, seq_len, num_dim)\n",
    "    output:\n",
    "        tensor size of (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden = 64, num_layers = 2, dropout = 0.5):\n",
    "        super(TS_rnn, self).__init__()\n",
    "        #change the structure of the network\n",
    "        num_inp = 21\n",
    "        self.rnn = torch.nn.LSTM(input_size = num_inp, hidden_size = num_hidden, num_layers = num_layers, dropout = dropout)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_hidden, 16),\n",
    "                torch.nn.Dropout(),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(16, 1)\n",
    "                )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # input of the rnn (seq_len, batch, input_size)\n",
    "        data_in = torch.transpose(inp, 0, 1)\n",
    "        # run rnn, it has two output\n",
    "        out_rnn, _ = self.rnn(data_in)\n",
    "        out_rnn = torch.transpose(out_rnn, 0, 1) # (batch_size, seq_len, num_dim)\n",
    "        # rnn the mlp\n",
    "        batch_size, seq_len, num_dim = out_rnn.shape\n",
    "        out = []\n",
    "        for i in range(seq_len):\n",
    "            tmp = self.mlp(out_rnn[:, i,:])\n",
    "            out.append(tmp)\n",
    "        # now out is list of (batch_size, 1), combine the items in the list to get the output with size (batch_size, seq_len)\n",
    "        out = torch.cat(out, 1)\n",
    "        #return out.squeeze() when the batch_size == 1, this can course trouble\n",
    "        return out\n",
    "\n",
    "class TS_rnn2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    scores only for the whole task\n",
    "    input:\n",
    "        tensor size of (batch_size, seq_len, num_dim)\n",
    "    output:\n",
    "        tensor size of (batch_size)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TS_rnn2, self).__init__()\n",
    "        #change the structure of the network\n",
    "        num_inp = 8\n",
    "        num_hidden = 64\n",
    "        self.rnn = torch.nn.LSTM(input_size = num_inp, hidden_size = num_hidden, num_layers = 2)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_hidden, 64),\n",
    "                torch.nn.Dropout(),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 1)\n",
    "                )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # input of the rnn (seq_len, batch, input_size)\n",
    "        data_in = torch.transpose(inp, 0, 1)\n",
    "        # run rnn, it has two output\n",
    "        out_rnn, _ = self.rnn(data_in)\n",
    "        out_rnn = torch.transpose(out_rnn, 0, 1) # (batch_size, seq_len, num_dim)\n",
    "        # only use the last output\n",
    "        out_rnn = out_rnn[:, -1, :].squeeze()\n",
    "        # rnn the mlp\n",
    "        out = self.mlp(out_rnn)\n",
    "        return out.squeeze()\n",
    "    \n",
    "class PDLoss(torch.nn.Module):\n",
    "    def __init__(self, p = 2):\n",
    "        super(PDLoss, self).__init__()\n",
    "        self.pd = torch.nn.PairwiseDistance(p)\n",
    "\n",
    "    def forward(self, o, t):\n",
    "        # out: (batch_size, 1)\n",
    "        out = self.pd(o, t)\n",
    "        return out.mean()\n",
    "\n",
    "class Data:\n",
    "    \"\"\"\n",
    "    data class for TS_rnn\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.data = {}\n",
    "        self.data['train_x'] = self.add_file(x)\n",
    "        self.data['train_y'] = self.add_file(y)[:, :, -1] # use the first metric tempately\n",
    "        assert(len(self.data['train_x']) == len(self.data['train_y']))\n",
    "        self.len = len(self.data['train_x'])\n",
    "\n",
    "    def add_file(self, path):\n",
    "        return torch.from_numpy(np.load(path))\n",
    "\n",
    "    def add_scores(self, path):\n",
    "        return torch.FloatTensor([float(li.rstrip('\\n')) for li in open(path)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data['train_x'][index],\n",
    "                self.data['train_y'][index])\n",
    "\n",
    "class Data2:\n",
    "    \"\"\"\n",
    "    data class for TS_rnn2\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.data = {}\n",
    "        self.data['train_x'] = self.add_file(x)\n",
    "        self.data['train_y'] = self.add_file(y)[:, :, -1] # use the first metric tempately\n",
    "        self.data['train_y'] = torch.mean(self.data['train_y'], 1)\n",
    "        assert(len(self.data['train_x']) == len(self.data['train_y']))\n",
    "        self.len = len(self.data['train_x'])\n",
    "\n",
    "    def add_file(self, path):\n",
    "        return torch.from_numpy(np.load(path))\n",
    "\n",
    "    def add_scores(self, path):\n",
    "        return torch.FloatTensor([float(li.rstrip('\\n')) for li in open(path)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data['train_x'][index],\n",
    "                self.data['train_y'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the test function\n",
    "def test_model(dl_test, model, loss):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    counter = 0\n",
    "    for batch_idx, dat in enumerate(dl_test):\n",
    "        counter += 1\n",
    "        # codes to be changed\n",
    "        inp, target = dat\n",
    "        out = model(inp)\n",
    "        lo = loss(out, target.squeeze())\n",
    "        test_loss += lo.data\n",
    "    return test_loss/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_state_to_input(state, df):\n",
    "    \"\"\"\n",
    "    FIXED STRUCTURE!!!\n",
    "    input: \n",
    "      state, type of list of tuple, tuple contains: (type of part, rotation)\n",
    "        sequence of inputted parts\n",
    "      df, type of Dataframe, \n",
    "        inlucde all the needed features(after norm)\n",
    "    output:\n",
    "      out, type of torch.FloatTensor\n",
    "        data, that can be used as input of the neural network.\n",
    "    \"\"\"\n",
    "    df_tmp = []\n",
    "    for i in state:\n",
    "        df_tmp.append(df[df['type'] == i[0]])\n",
    "    df_tmp = pd.concat(df_tmp)\n",
    "    df_tmp['rotation'] = [i[1] for i in state]\n",
    "    df_tmp['r1'] = df_tmp['rotation'].map(lambda x: 0 if x == 90 else 1)\n",
    "    df_tmp['r2'] = df_tmp['rotation'].map(lambda x: 1 if x == 90 else 0)\n",
    "    # do features selection to make sure that all the features are included and in a right sequence.\n",
    "    df_tmp = df_tmp[['norm_area', 'length', 'num_of_corr', 'A/L', \n",
    "                            'area quote', 'convex area quote', 'centroid x/width',\n",
    "                            'centroid y/height', 'width/height', 'convex area','area verhaltnis',\n",
    "                            'r1', 'r2', 'wv0', 'wv1', 'wv2', 'wv3', 'wv4', 'wv5', 'wv6', 'wv7']]\n",
    "    out = df_tmp.values.reshape(1, len(state), -1)\n",
    "    return torch.from_numpy(out).float()\n",
    "def transform_state_to_input_batch(states, df):\n",
    "    \"\"\"\n",
    "    FIXED STRUCTURE!!!\n",
    "    input:\n",
    "        state, type of list of list of tuple, tuple contains: (type of part, rotation)\n",
    "          list of sequence of inputted parts\n",
    "        df, type of Dataframe,\n",
    "          include all the needed fetures(after norm)\n",
    "    output:\n",
    "        out, type of torch.FloatTensor\n",
    "          data, that can be used as input of neural network\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    if len(states) == 1:\n",
    "        print('i\\'am signle+++++++++++')\n",
    "        return transform_state_to_input(state, df)\n",
    "    for state in states:\n",
    "        out.append(transform_state_to_input(state, df))\n",
    "    out = torch.cat(out, dim = 0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 3.5000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7452212444386584\n",
      "0.7864392640882858\n",
      "0.5350374114846711\n",
      "0.8246176146286697\n",
      "0.15332075141461254\n",
      "0.5488911329159931\n",
      "0.9850457069469725\n",
      "0.25227962668449744\n",
      "0.9556988744732919\n",
      "0.4109676803176785\n",
      "0.9115692918311433\n",
      "0.7752926547061428\n",
      "0.11904452203082005\n",
      "0.7073897844238803\n",
      "0.5647629451200096\n",
      "0.8463210903422226\n",
      "0.677832289642098\n",
      "0.569786642081917\n",
      "0.3440835397424752\n",
      "0.916832655857401\n",
      "0.5193944264001072\n",
      "0.15542754211437226\n",
      "0.0558404698601328\n",
      "0.37803181176908496\n",
      "0.8588235974015574\n",
      "0.21799822757673604\n",
      "0.7744060618250113\n",
      "0.09960030267307074\n",
      "0.41829617127118546\n",
      "0.09771360028568321\n",
      "0.3207983633745609\n",
      "0.5634766591117167\n",
      "0.8268425134779395\n",
      "0.19400343063203862\n",
      "0.7074899581782949\n",
      "0.17813748853048494\n",
      "0.55886122047754\n",
      "0.6714994474056385\n",
      "0.1412716973461431\n",
      "0.8289008779899285\n",
      "0.5885650565870666\n",
      "0.7404225617219523\n",
      "0.0360887845265192\n",
      "0.9149751489598441\n",
      "0.5738259025347254\n",
      "0.41063877692273076\n",
      "0.5123768662390771\n",
      "0.2891863280021443\n",
      "0.6397155598550128\n",
      "0.1549018512098025\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
